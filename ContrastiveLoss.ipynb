{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eff78118",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Importing neccessary modules\"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import cv2\n",
    "import math\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from numpy import random\n",
    "from keras_facenet import FaceNet\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score , roc_curve\n",
    "from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from tensorflow.keras.models import Model\n",
    "from keras.layers import Dense , Flatten , Input ,BatchNormalization , concatenate , Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b2e1fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"we will use pretrained model which will take 160*160*3 size images as input\"\"\"\n",
    "from tensorflow.keras.models import load_model\n",
    "img_shape = (160,160,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "307d80b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Read the image to ie convert them into np array\"\"\"\n",
    "def read_image(img):\n",
    "    image = cv2.imread(img)\n",
    "    image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95cd868a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Names of celebrity on whom images model will be trained\"\"\"\n",
    "names = [\n",
    "    'alexandro_dadario','aishwarya_rae','burak_deniz','chris_hemsworth','elon_musk','gayatri_bharadwaj',\n",
    "    'hande_ercel','virat_kohli','ronaldo','sushant','samantha','hritik_roshan','priyanka_chopra',\n",
    "    'nidhi_agarwal','kit_harington','kristen_stewart','nayantra','rasmika_mandhana','sundar_pichai',\n",
    "    'zayn_malik','vicky_kaushal','ana_de_armas','amber_heard','chris_evans','DeepikaPadukone','mahesh_babu',\n",
    "    'modiji','priya','sanjana_sanghi','scarlet_johnson'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bba69c27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fec8c32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Mapping each celebrity number\"\"\"\n",
    "names_to_label = {}\n",
    "labels_to_name = {}\n",
    "faces = {}\n",
    "imgshape = (160,160,3)\n",
    "cnt = len(glob.glob('./New_data/**/*.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1137debe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Mappped\"\"\"\n",
    "for i,name in enumerate(names):\n",
    "    names_to_label[name] = i\n",
    "    labels_to_name[i] = name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebd52e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Read + preprocessing image\"\"\"\n",
    "def readimage(url):\n",
    "    img = cv2.imread(url)\n",
    "    img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "    img = np.asarray(img).astype('float32')\n",
    "    img = cv2.resize(img,(160,160))\n",
    "    img = img/255.0\n",
    "    return img\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b79cb24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = len(glob.glob('./New_data/**/*.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c625b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"X and y to store the images , dataset + label\"\"\"\n",
    "X = np.zeros((cnt,)+img_shape,dtype='float32')\n",
    "y = np.zeros(cnt,dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69779159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3524, 160, 160, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "867c1cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,img in enumerate(glob.glob('./New_data/**/*.jpg')):\n",
    "    X[i] = readimage(img)\n",
    "    name = img.split('/')[2]\n",
    "    y[i] = names_to_label[name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17d5be39",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Split the dataset into 3 parts \n",
    "1. training\n",
    "2.validation\n",
    "3. test\n",
    "stratified random sampling performed before spliting\n",
    "\"\"\"\n",
    "X_train ,  X_test , y_train, y_test = \\\n",
    "        train_test_split(X,y,shuffle=True,stratify=y,random_state=42,test_size=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0cae192",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train ,  X_val , y_train, y_val = \\\n",
    "        train_test_split(X_train,y_train,shuffle=True,stratify=y_train,random_state=42,test_size=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e0cc233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"Function to create image pair(they could be of same or different person) , with the label of 0 if they are same ,\n",
    "# else 0\"\"\"\n",
    "# def make_pair(X,y):\n",
    "#     num_class = np.unique(y).shape[0] # number of classes \n",
    "#     indices_pos = [np.squeeze(np.where(y == i)) for i in range(num_class)] # index of same celebrity images as anchor\n",
    "#     indices_neg = [np.squeeze(np.where(y != i)) for i in range(num_class)] # index of different celebrity from anchor\n",
    "    \n",
    "    \n",
    "#     pairs , labels = [] ,[]\n",
    "    \n",
    "#     for idx in range(X.shape[0]):\n",
    "#         anchor = X[idx] # anchor image\n",
    "#         label = int(y[idx]) # anchor image label\n",
    "        \n",
    "#         positive = X[np.random.choice(indices_pos[label])] # positive image\n",
    "#         negative = X[np.random.choice(indices_neg[label])] # negative image\n",
    "        \n",
    "#         pairs += [[anchor, positive]] # creating a pair of anchor + positive\n",
    "#         labels += [1] # corresponding label of 1 as both image is of same person\n",
    "        \n",
    "#         pairs += [[anchor, negative]] # creating a pair of anchor + negative\n",
    "#         labels += [0] # corresponding label of 0 as both image is of different person\n",
    "        \n",
    "#     return np.array(pairs), np.array(labels).astype('float32')\n",
    "\n",
    "def make_pair(X,y):\n",
    "    num_class =np.unique(y).shape[0]\n",
    "    indices_pos = [np.squeeze(np.where(y == i)) for i in range(num_class)]\n",
    "    indices_neg = [np.squeeze(np.where(y != i)) for i in range(num_class)]\n",
    "    \n",
    "    \n",
    "    pairs , labels = [] ,[]\n",
    "    \n",
    "    for idx in range(X.shape[0]):\n",
    "        x1 = X[idx]\n",
    "        label = int(y[idx])\n",
    "        \n",
    "        x2 = X[np.random.choice(indices_pos[label])]\n",
    "        x3 = X[np.random.choice(indices_neg[label])]\n",
    "        \n",
    "        pairs += [[x1, x2]]\n",
    "        labels += [1]\n",
    "        \n",
    "        pairs += [[x1, x3]]\n",
    "        labels += [0]\n",
    "        \n",
    "    return np.array(pairs), np.array(labels).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488f4190",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c789d084",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Trainng pairs\"\"\"\n",
    "pair_train , labels_train= make_pair(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "162b2144",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Test pair\"\"\"\n",
    "pair_test , labels_test= make_pair(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7fb17ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Validation pair\"\"\"\n",
    "pair_val , labels_val= make_pair(X_val,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "faf602e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_1 = pair_train[:, 0]  \n",
    "x_train_2 = pair_train[:, 1]\n",
    "\n",
    "x_val_1 = pair_val[:, 0]  \n",
    "x_val_2 = pair_val[:, 1]\n",
    "\n",
    "x_test_1 = pair_test[:, 0]  \n",
    "x_test_2 = pair_test[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ff676205",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Model will output 128 dimenstion vector from the image, we will calculate the euclidean distance\"\"\"\n",
    "def euclidean_distance(vects):\n",
    "    x, y = vects # vector is a pair \n",
    "#   Formula of euclidean distance sqrt(x1-x2)*(x1-x2) + (y1-y2)*(y1-y2))\n",
    "    sum_square = tf.math.reduce_sum(tf.math.square(x - y), axis=1, keepdims=True)\n",
    "    return tf.math.sqrt(tf.math.maximum(sum_square, tf.keras.backend.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "62ffffce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Importing pretrained model\"\"\"\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2 , preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4a5df798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-04 09:46:09.833143: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-08-04 09:46:09.833759: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "'''Creating an instance of it'''\n",
    "resnet = InceptionResNetV2(include_top=False,weights='imagenet',input_shape=img_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c1dfdaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Creating function Cnn model , we will take the output of InceptionResnetv2 model'''\n",
    "x = resnet.layers[-1].output\n",
    "x = Flatten()(x) # flatten the output of resnet model output\n",
    "x = Dense(512,activation='relu')(x) # applying ANN to reduce it to 512 vector size\n",
    "out = Dense(128,activation='relu')(x) # further to  128\n",
    "model = Model(resnet.input,out)\n",
    "# Above model will take an image as input and will return a 128 sized vector , which is the embedding of each iamge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ba949733",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_1 =Input(img_shape)\n",
    "input_2 = Input(img_shape)\n",
    "\n",
    "tower_1 = model(input_1)\n",
    "tower_2 = model(input_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a875e9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Merge the image pairs embeddings, normalise them , further applying Ann to reduce final output to 1 sized vector\"\"\"\n",
    "merge_layer = Lambda(euclidean_distance)([tower_1, tower_2])\n",
    "normal_layer = BatchNormalization()(merge_layer)\n",
    "output_layer = Dense(1, activation=\"sigmoid\")(normal_layer)\n",
    "siamese = Model(inputs=[input_1, input_2], outputs=output_layer)\n",
    "# Above siamese model take a pair as input , an return a number , which if close to 1 means they belongs to same person \n",
    "# if close to 0 , belongs to different persons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874f0392",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(margin=1):\n",
    "    # Contrastive loss = mean( (1-true_value) * square(prediction) +\n",
    "    #                         true_value * square( max(margin-prediction, 0) ))\n",
    "    def contrastive_loss(y_true, y_pred):\n",
    "        \"\"\"Calculates the constrastive loss.\n",
    "\n",
    "        Arguments:\n",
    "            y_true: List of labels, each label is of type float32.\n",
    "            y_pred: List of predictions of same length as of y_true,\n",
    "                    each label is of type float32.\n",
    "\n",
    "        Returns:\n",
    "            A tensor containing constrastive loss as floating point value.\n",
    "        \"\"\"\n",
    "\n",
    "        square_pred = tf.math.square(y_pred)\n",
    "        margin_square = tf.math.square(tf.math.maximum(margin - (y_pred), 0))\n",
    "        return tf.math.reduce_mean(\n",
    "            (1 - y_true) * square_pred + (y_true) * margin_square\n",
    "        )\n",
    "\n",
    "    return contrastive_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8efac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "batch_size = 48\n",
    "margin = 1.5  # Margin for constrastive loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7add245",
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese.compile(loss=loss(margin=margin), optimizer=tf.optimizers.Adam(lr=0.0006), metrics=[\"accuracy\"])\n",
    "siamese.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7fdff676",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-03 16:41:07.334846: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-03 16:41:19.243918: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - ETA: 0s - loss: 0.5447 - accuracy: 0.6833"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-03 16:50:01.848807: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 564s 4s/step - loss: 0.5447 - accuracy: 0.6833 - val_loss: 0.4988 - val_accuracy: 0.7406\n",
      "Epoch 2/20\n",
      "119/119 [==============================] - 876s 7s/step - loss: 0.4727 - accuracy: 0.7611 - val_loss: 0.4771 - val_accuracy: 0.7500\n",
      "Epoch 3/20\n",
      "119/119 [==============================] - 554s 5s/step - loss: 0.4191 - accuracy: 0.8144 - val_loss: 0.4182 - val_accuracy: 0.7940\n",
      "Epoch 4/20\n",
      "119/119 [==============================] - 588s 5s/step - loss: 0.3711 - accuracy: 0.8533 - val_loss: 0.4192 - val_accuracy: 0.8003\n",
      "Epoch 5/20\n",
      "119/119 [==============================] - 556s 5s/step - loss: 0.3283 - accuracy: 0.8824 - val_loss: 0.3627 - val_accuracy: 0.8223\n",
      "Epoch 6/20\n",
      "119/119 [==============================] - 642s 5s/step - loss: 0.2938 - accuracy: 0.9040 - val_loss: 0.3291 - val_accuracy: 0.8616\n",
      "Epoch 7/20\n",
      "119/119 [==============================] - 640s 5s/step - loss: 0.2699 - accuracy: 0.9152 - val_loss: 0.3196 - val_accuracy: 0.8428\n",
      "Epoch 8/20\n",
      "119/119 [==============================] - 619s 5s/step - loss: 0.2479 - accuracy: 0.9338 - val_loss: 0.3032 - val_accuracy: 0.8569\n",
      "Epoch 9/20\n",
      "119/119 [==============================] - 667s 6s/step - loss: 0.2293 - accuracy: 0.9450 - val_loss: 0.2889 - val_accuracy: 0.8774\n",
      "Epoch 10/20\n",
      "119/119 [==============================] - 608s 5s/step - loss: 0.2157 - accuracy: 0.9550 - val_loss: 0.2953 - val_accuracy: 0.8632\n",
      "Epoch 11/20\n",
      "119/119 [==============================] - 582s 5s/step - loss: 0.2037 - accuracy: 0.9625 - val_loss: 0.2704 - val_accuracy: 0.8947\n",
      "Epoch 12/20\n",
      "119/119 [==============================] - 618s 5s/step - loss: 0.1944 - accuracy: 0.9671 - val_loss: 0.2742 - val_accuracy: 0.8711\n",
      "Epoch 13/20\n",
      "119/119 [==============================] - 593s 5s/step - loss: 0.1822 - accuracy: 0.9748 - val_loss: 0.3044 - val_accuracy: 0.8113\n",
      "Epoch 14/20\n",
      "119/119 [==============================] - 780s 7s/step - loss: 0.1737 - accuracy: 0.9818 - val_loss: 0.2577 - val_accuracy: 0.8947\n",
      "Epoch 15/20\n",
      "119/119 [==============================] - 700s 6s/step - loss: 0.1667 - accuracy: 0.9839 - val_loss: 0.2602 - val_accuracy: 0.8931\n",
      "Epoch 16/20\n",
      "119/119 [==============================] - 613s 5s/step - loss: 0.1647 - accuracy: 0.9855 - val_loss: 0.2507 - val_accuracy: 0.8915\n",
      "Epoch 17/20\n",
      "119/119 [==============================] - 587s 5s/step - loss: 0.1589 - accuracy: 0.9890 - val_loss: 0.2446 - val_accuracy: 0.8994\n",
      "Epoch 18/20\n",
      "119/119 [==============================] - 628s 5s/step - loss: 0.1562 - accuracy: 0.9884 - val_loss: 0.2467 - val_accuracy: 0.8931\n",
      "Epoch 19/20\n",
      "119/119 [==============================] - 753s 6s/step - loss: 0.1515 - accuracy: 0.9923 - val_loss: 0.2673 - val_accuracy: 0.8774\n",
      "Epoch 20/20\n",
      "119/119 [==============================] - 876s 7s/step - loss: 0.1543 - accuracy: 0.9883 - val_loss: 0.2302 - val_accuracy: 0.9104\n"
     ]
    }
   ],
   "source": [
    "history = siamese.fit(\n",
    "    [x_train_1, x_train_2],\n",
    "    labels_train,\n",
    "    validation_data=([x_val_1, x_val_2], labels_val),\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "#     callbacks=EarlyStopping(monitor='val_loss' , patience=5,min_delta=0.1)x\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "45003580",
   "metadata": {},
   "outputs": [],
   "source": [
    "pa = load_model('./NewDataSiameseModel.h5',compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087983fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703b6b12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3ed4ebf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix , accuracy_score , recall_score , precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ade3bb29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-04 09:47:27.021597: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-08-04 09:47:29.024737: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 19s 613ms/step\n"
     ]
    }
   ],
   "source": [
    "p1 = pa.predict([x_test_1,x_test_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "78f0d260",
   "metadata": {},
   "outputs": [],
   "source": [
    "yp1 = np.where(p1>=0.5,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e95e9613",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(706,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "79aa0cb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[302,   8],\n",
       "       [ 51, 345]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(yp1,labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a521a941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9164305949008499, 0.9773371104815864, 0.8712121212121212)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(yp1,labels_test) , precision_score(yp1,labels_test) , recall_score(yp1,labels_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9acf947",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
